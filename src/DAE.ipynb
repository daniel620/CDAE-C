{"cells":[{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from tensorflow.keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Sequential, Model, save_model, load_model\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D,MaxPool2D ,UpSampling2D, Flatten, Input\n","from tensorflow.keras.optimizers import Adam\n","# adam = adam_v2.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import regularizers\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n","import cv2\n","from math import log10,sqrt\n","from PIL import Image\n","%matplotlib inline"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"functional_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_layer (InputLayer)     [(None, None, None, 1)]   0         \n","_________________________________________________________________\n","encoder_conv_1 (Conv2D)      (None, None, None, 128)   1280      \n","_________________________________________________________________\n","encoder_pool_1 (MaxPooling2D (None, None, None, 128)   0         \n","_________________________________________________________________\n","encoder_conv_2 (Conv2D)      (None, None, None, 64)    73792     \n","_________________________________________________________________\n","latent_code_layer (MaxPoolin (None, None, None, 64)    0         \n","_________________________________________________________________\n","decoder_conv_1 (Conv2D)      (None, None, None, 64)    36928     \n","_________________________________________________________________\n","decoder_upsample_1 (UpSampli (None, None, None, 64)    0         \n","_________________________________________________________________\n","decoder_conv_2 (Conv2D)      (None, None, None, 128)   73856     \n","_________________________________________________________________\n","decoder_upsample_2 (UpSampli (None, None, None, 128)   0         \n","_________________________________________________________________\n","output_layer (Conv2D)        (None, None, None, 1)     1153      \n","=================================================================\n","Total params: 187,009\n","Trainable params: 187,009\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"functional_11\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_layer (InputLayer)     [(None, None, None, 1)]   0         \n","_________________________________________________________________\n","encoder_conv_1 (Conv2D)      (None, None, None, 128)   1280      \n","_________________________________________________________________\n","encoder_pool_1 (MaxPooling2D (None, None, None, 128)   0         \n","_________________________________________________________________\n","encoder_conv_2 (Conv2D)      (None, None, None, 64)    73792     \n","_________________________________________________________________\n","latent_code_layer (MaxPoolin (None, None, None, 64)    0         \n","=================================================================\n","Total params: 75,072\n","Trainable params: 75,072\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["'''\n","Model Construction: autoencoder, or CDAE\n","'''\n","def autoencoder():\n","  input_img=Input(shape=(28,28,1),name='image_input')\n","  #enoder \n","  x = Conv2D(128, (3,3), activation='relu', padding='same', name='Conv1')(input_img)\n","  x = MaxPooling2D((2,2), padding='same', name='pool1')(x)\n","  x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv2')(x)\n","  x = MaxPooling2D((2,2), padding='same', name='pool2')(x)\n","\n","  #decoder\n","  x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv3')(x)\n","  x = UpSampling2D((2,2), name='upsample1')(x)\n","  x = Conv2D(128, (3,3), activation='relu', padding='same', name='Conv4')(x)\n","  x = UpSampling2D((2,2), name='upsample2')(x)\n","  x = Conv2D(1, (3,3), activation='sigmoid', padding='same', name='Conv5')(x)\n","  #model\n","  autoencoder = Model(inputs=input_img, outputs=x)\n","  autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","  autoencoder.summary()\n","  return autoencoder\n","\n","def CDAE():\n","  input_img=Input(shape=(None,None,1),name='input_layer')\n","  encoding_dim_1 = 128\n","  encoding_dim_2 = 64\n","  decoding_dim_2 = encoding_dim_2\n","  decoding_dim_1 = encoding_dim_1\n","  sparsity=False\n","  if sparsity:\n","    reg = regularizers.l2(10e-5)\n","  else: \n","    reg = None\n","  #enoder \n","  x = Conv2D(encoding_dim_1, (3,3), activation='relu', padding='same', name='encoder_conv_1',kernel_regularizer=reg)(input_img)\n","  x = MaxPooling2D((2,2), padding='same', name='encoder_pool_1')(x)\n","  x = Conv2D(encoding_dim_2, (3,3), activation='relu', padding='same', name='encoder_conv_2',kernel_regularizer=reg)(x)\n","  latent_code = MaxPooling2D((2,2), padding='same', name='latent_code_layer')(x)\n","\n","  #decoder\n","  x = Conv2D(decoding_dim_2, (3,3), activation='relu', padding='same', name='decoder_conv_1')(latent_code)\n","  x = UpSampling2D((2,2), name='decoder_upsample_1')(x)\n","  x = Conv2D(decoding_dim_1, (3,3), activation='relu', padding='same', name='decoder_conv_2')(x)\n","  x = UpSampling2D((2,2), name='decoder_upsample_2')(x)\n","  denoised_img = Conv2D(1, (3,3), activation='sigmoid', padding='same', name='output_layer')(x)\n","  #model\n","  autoencoder = Model(inputs=input_img, outputs=denoised_img)\n","  encoder = Model(inputs=input_img, outputs=latent_code)\n","\n","  autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","  autoencoder.summary()\n","  encoder.summary()\n","  return autoencoder, encoder\n","\n","model, encoder=CDAE()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["raw: (260,) noisy: (58,)\n","raw_data shape: (58, 256, 256)\n","noisy_data shape: (58, 256, 256)\n","train scale: 46\n","test scale: 12\n"]}],"source":["'''\n","Data preparation\n","'''\n","# read data\n","raw_imgs = pd.read_csv('../data/preprocess/1-raw_bmp.csv')\n","raw_imgs = raw_imgs.iloc[:,:].values.reshape(-1)\n","noisy_imgs = pd.read_csv('../data/preprocess/3-noisy_bmp.csv')\n","noisy_imgs = noisy_imgs.iloc[:,:].values.reshape(-1)\n","print('raw:', raw_imgs.shape, 'noisy:',noisy_imgs.shape)\n","raw_data = []\n","noisy_data = []\n","if len(noisy_imgs) < len(raw_imgs):\n","    for i in range(len(noisy_imgs)):\n","        raw_img = np.array(Image.open(raw_imgs[i]).resize((256,256),Image.LANCZOS))/ 255\n","        noisy_img = np.array(Image.open(noisy_imgs[i]).resize((256,256),Image.LANCZOS))/ 255\n","        raw_data.append(raw_img)\n","        noisy_data.append(noisy_img)\n","        # plt.imshow(image,cmap='gray')\n","\n","# raw_data, (n ,None, None, 1)\n","raw_data = np.array(raw_data)\n","print('raw_data shape:',raw_data.shape)\n","# noisy data (n, None, None, 1)\n","noisy_data = np.array(noisy_data)\n","print('noisy_data shape:',noisy_data.shape)\n","'''Split into 80% train and 20% test dataset'''\n","total_num = raw_data.shape[0]\n","train_num = int(0.8*total_num)\n","raw_train = raw_data[:train_num] \n","raw_test = raw_data[train_num:]\n","noisy_train = noisy_data[:train_num] \n","noisy_test = noisy_data[train_num:] \n","print('train scale:', raw_train.shape[0])\n","print('test scale:', raw_test.shape[0])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","5/5 [==============================] - 13s 3s/step - loss: 0.6762 - val_loss: 0.6259\n","Epoch 2/10\n","5/5 [==============================] - 12s 2s/step - loss: 0.5760 - val_loss: 0.4931\n","Epoch 3/10\n","5/5 [==============================] - 12s 2s/step - loss: 0.5023 - val_loss: 0.4847\n","Epoch 4/10\n","5/5 [==============================] - 11s 2s/step - loss: 0.4900 - val_loss: 0.4899\n","Epoch 5/10\n","5/5 [==============================] - 12s 2s/step - loss: 0.4871 - val_loss: 0.4847\n","Epoch 6/10\n","5/5 [==============================] - 13s 3s/step - loss: 0.4860 - val_loss: 0.4801\n","Epoch 7/10\n","5/5 [==============================] - 11s 2s/step - loss: 0.4838 - val_loss: 0.4788\n","Epoch 8/10\n","5/5 [==============================] - 10s 2s/step - loss: 0.4825 - val_loss: 0.4784\n","Epoch 9/10\n","5/5 [==============================] - 12s 2s/step - loss: 0.4820 - val_loss: 0.4776\n","Epoch 10/10\n","5/5 [==============================] - 10s 2s/step - loss: 0.4817 - val_loss: 0.4772\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fa6b40ef190>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n","model.fit(raw_train, noisy_train, epochs=10, batch_size=10,validation_data=(raw_test, noisy_test), callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1, 356, 356, 1)\n"]}],"source":["pred = model.predict(np.random.rand(1,354,354,1))\n","print(pred.shape)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1, 4, 4, 64)\n","[[[[0.01501302 0.09600578 0.02295821 ... 0.07253284 0.0694368\n","    0.05218992]\n","   [0.         0.10938805 0.02413249 ... 0.09230495 0.12025043\n","    0.04631273]\n","   [0.0021054  0.08095233 0.         ... 0.0719962  0.10252042\n","    0.061949  ]\n","   [0.         0.08799984 0.         ... 0.08511876 0.09830785\n","    0.03206883]]\n","\n","  [[0.0284171  0.12478039 0.         ... 0.09140285 0.14580013\n","    0.0459504 ]\n","   [0.00049037 0.12886341 0.         ... 0.09260084 0.10948381\n","    0.04271192]\n","   [0.         0.09428765 0.         ... 0.1045905  0.15196282\n","    0.06477398]\n","   [0.         0.10729371 0.         ... 0.07143067 0.11175463\n","    0.07940578]]\n","\n","  [[0.         0.13522968 0.         ... 0.11333944 0.12424037\n","    0.03797133]\n","   [0.         0.11125959 0.         ... 0.09956174 0.12730707\n","    0.063302  ]\n","   [0.         0.12939264 0.         ... 0.07404501 0.12269968\n","    0.04058091]\n","   [0.         0.11487411 0.         ... 0.08913933 0.12482999\n","    0.03784287]]\n","\n","  [[0.00516936 0.12170374 0.         ... 0.11281694 0.13638228\n","    0.        ]\n","   [0.         0.14164132 0.         ... 0.09780292 0.1283326\n","    0.04434844]\n","   [0.         0.12741773 0.         ... 0.09339797 0.15897101\n","    0.02312165]\n","   [0.         0.1072604  0.         ... 0.08943788 0.08617043\n","    0.0486385 ]]]]\n"]}],"source":["# test\n","img_rand = np.random.rand(1,16,16,1)\n","pred_before_train = encoder.predict(img_rand)\n","print(pred_before_train.shape)\n","print(pred_before_train)\n","# after training\n","pred_before_train = encoder.predict(img_rand)\n","print(pred_before_train.shape)\n","print(pred_before_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","Model Training\n","'''\n","# if GPU available\n","with tf.device('/device:GPU:0'):\n","    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n","    CDAE.fit(raw_train, noisy_train, epochs=100, batch_size=10, validation_data=(raw_test, noisy_test), callbacks=[early_stopping,TensorBoard(log_dir=r\"/data-output/DAE_test\",\n","                        histogram_freq=1,update_freq=\"batch\")])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","Prediction\n","'''\n","pred_denoised_img = model.predict(noisy_test[:5])\n","pred_latent_code = encoder.predict(noisy_test[:5])"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjwAAAA9CAYAAACpzLMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADs0lEQVR4nO3bPUscCxgF4JlLghAEQbGyC5bxIyAYsBJNFmMn2CiKhVrHn2CTSoKttWWK2KixCyiKYqGCpVXEUtBSiJM/YHaW+0YCL89TOnN25zC6exiwrKqqAADI7L9/fQEAAM/N4AEA0jN4AID0DB4AID2DBwBIz+ABANJ70ezg3t5e6H/WG41GJF4MDAyE8ufn52XdOTMzM6GO/f39kXjR1dUVyi8tLdV2vL+/D3VcW1uLxIuFhYVQ/vXr1007lmUZ6vfu3btIvHh8fAzlj4+Pa+/hzc1NqOPl5WUkXkxOTobyDw8PtR2Hh4dDHXd3dyPxorOzM5QviqK24/r6+j/9vBkbGwvlq6pq2nFrayvU79WrV5F48fnz51D+x48ftfewvb091HF2djYSL7a3t0P56+vrZ/9bPDk5icSL79+/h/KNRuPJjp7wAADpGTwAQHoGDwCQnsEDAKRn8AAA6Rk8AEB6Bg8AkJ7BAwCkZ/AAAOkZPABAegYPAJCewQMApGfwAADpGTwAQHovmh0cHR0NvfibN29C+Z6enlC+FVNTU6H89PT0X7qS/2dpaan2nPn5+dB7bG1thfJlWYbyVVU1PT44OBh6/aOjo1B+eXk5lG/FxcVFKH93dxfKr6+vh/KtWFxcDOVHRkZC+S9fvoTyExMTteecnJyE3uPTp0+h/MPDQyhf5+zsLJRfXV0N5es+K/6G6DW+f/8+lN/Y2AjlW/H169dQ/vb2NpRfWVkJ5RuNxpM/94QHAEjP4AEA0jN4AID0DB4AID2DBwBIz+ABANIzeACA9AweACA9gwcASM/gAQDSM3gAgPQMHgAgPYMHAEjP4AEA0jN4AID0yqqq/nhwdXX1zwdbsLKyEokXHR0doXxVVWUrp0Xeo6+vLxIvTk9PQ/m2trbajnNzc6GO+/v7kXjx7du3UP7t27dNO97f34f6jY2NReLF4eFhKP/y5cvae9jb2xvqeHV1FYkXzT4nWlTbsSzL0JuMj49H4sXOzk4o38p9/PnzZ6jj0NBQJF58+PAhlN/c3Gza8eDgINRvdnY2Ei+6u7tD+dPT02f/PY1+ry0uLobya2trz/69+PHjx0i8+PXrVyi/t7f3ZEdPeACA9AweACA9gwcASM/gAQDSM3gAgPQMHgAgPYMHAEjP4AEA0jN4AID0DB4AID2DBwBIz+ABANIzeACA9AweACA9gwcASK+squpfXwMAwLPyhAcASM/gAQDSM3gAgPQMHgAgPYMHAEjP4AEA0vsN1oW8Z1jz318AAAAASUVORK5CYII=","text/plain":["<Figure size 720x288 with 10 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["'''\n","Weights Visiualization\n","'''\n","def plot_weights_matrix(model, layer_name, n_neurons):\n","    \"\"\"\n","    Plots the weight matrix of the first `n_neurons` neurons of a layer in the given model.\n","    \n","    The kernel of the given layer has dimensions input_shape x output_shape. We slice this\n","    matrix by the axis of the output_shape and display each of the slices reshaped to a quadratic\n","    picture.\n","    \n","    INPUT:\n","        model: A trained Keras model\n","        layer_name (string): name of the layer whose weight matrix shall be shown\n","        n_neurons (int): number of neurons to be visualized\n","    \"\"\"\n","    kernel_eval = K.eval(model.get_layer(layer_name).kernel)\n","    \n","    # dimension for weight matrix plot\n","    # dim = int(np.sqrt(kernel_eval.T[0].shape)[0])\n","    dim = 3    \n","    # plot the first n_neurons neurons\n","    fig = plt.figure(figsize=(n_neurons, 4))\n","    for i in range(n_neurons):\n","        plt.subplot(1, n_neurons, i + 1)\n","        plt.imshow(kernel_eval.T[i].reshape(dim, dim), cmap='gray')\n","        plt.axis('off')\n","    plt.show()\n","plot_weights_matrix(encoder,'encoder_conv_1',10)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["'''\n","Model save \n","'''\n","def save_CDAE(model,encoder,id=None):\n","    save_dir_path = '../weights/'\n","    model_id_list = []\n","    if not os.path.exists(save_dir_path):\n","        os.mkdir(save_dir_path)\n","    else:\n","        for file_name in os.listdir(save_dir_path):\n","            if file_name.endswith('.h5'):\n","                model_id_list.append(int(file_name[-4]))\n","    if not id:\n","        id = 0\n","        if len(model_id_list) > 0:\n","            id = max(model_id_list) + 1\n","    save_model(model,save_dir_path + 'CDAE_model_'+str(id)+'.h5')\n","    save_model(encoder,save_dir_path + 'encoder_model_'+str(id)+'.h5')\n","save_CDAE(model,encoder,id=1)\n","\n","            # print(int(file_name[-4]))\n","# save_model(model,save_dir_path + 'CDAE_model_test1.h5')\n","# save_model(encoder,save_dir_path + 'encoder_model_test1.h5')\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"functional_11\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_layer (InputLayer)     [(None, None, None, 1)]   0         \n","_________________________________________________________________\n","encoder_conv_1 (Conv2D)      (None, None, None, 128)   1280      \n","_________________________________________________________________\n","encoder_pool_1 (MaxPooling2D (None, None, None, 128)   0         \n","_________________________________________________________________\n","encoder_conv_2 (Conv2D)      (None, None, None, 64)    73792     \n","_________________________________________________________________\n","latent_code_layer (MaxPoolin (None, None, None, 64)    0         \n","=================================================================\n","Total params: 75,072\n","Trainable params: 75,072\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["encoder_test.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"9ce4fd1792a08c55004df13a80be1ff164ae085b96fe91a2e77954f1292bca6d"},"kernelspec":{"display_name":"Python 3.7.4 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
